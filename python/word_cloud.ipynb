{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd87ea3-0078-4981-ba93-6367a37bc436",
   "metadata": {},
   "source": [
    "### Extracting cloud word data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf6afe-b7b6-43e8-b1f4-27b6e5452dde",
   "metadata": {},
   "source": [
    "A lot more can be done using the text book, we will now explore how to extract the word describing the most each book with the goal of doing a WordCloud like visualisation. To do so, we will need to reload the different file and convert each book into a very large string containing all the text of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f66ffb-8a4b-4db3-9ed3-0771f9618ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from helper.constantes import *\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83d74f5-54e3-4985-a60b-295053b4fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = []\n",
    "for i in range(1,8):\n",
    "    # Read the full book line by line in the a list\n",
    "    with open(data_folder+hpbooks_folder+f\"hp{i}.txt\") as f:\n",
    "        lines = f.readlines()\n",
    "    cur_str = \"\"\n",
    "    for line in lines:\n",
    "        cur_str += line\n",
    "    all_books.append(cur_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994a0091-a5e5-4196-8331-970a220f455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_return(corpus, min_df=0.2, max_df=1.0, ngram_range =(1,4)):\n",
    "    final_stopwords_list = stopwords.words('english')+ [\"said\", \"page\", \"mind\"]\n",
    "    tfidf = TfidfVectorizer(min_df=min_df,max_df=max_df,stop_words=final_stopwords_list, use_idf=True,ngram_range=ngram_range)\n",
    "    X = tfidf.fit_transform(corpus)\n",
    "    feature_names = np.array(tfidf.get_feature_names_out())\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95bf7a7-d2ea-4db0-bde8-0c23c60d93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_top_tf_idf_words(full_x, feature_names, top_n=2):\n",
    "    def get_top_tf_idf_words(x):\n",
    "        sorted_nzs = np.argsort(x.data)[:-(top_n+1):-1]\n",
    "        return feature_names[x.indices[sorted_nzs]]\n",
    "    return [get_top_tf_idf_words(cur) for cur in full_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9cb30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(words):\n",
    "    with open(\"word_cloud\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(words, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374bdd23-9294-4dd6-9b7e-1948ba99daac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['harry', 'potter', 'ron', 'stone', 'harry potter', 'hagrid',\n",
       "        'rowling', 'hermione', 'back', 'one', 'know', 'got', 'could',\n",
       "        'get', 'like', 'professor', 'see', 'snape', 'looked', 'quirrell',\n",
       "        'dumbledore', 'around', 'dudley', 'go', 'going'], dtype=object),\n",
       " array(['harry', 'ron', 'chamber secrets', 'potter', 'secrets', 'chamber',\n",
       "        'harry potter', 'rowling', 'lockhart', 'hermione', 'back', 'one',\n",
       "        'malfoy', 'could', 'dobby', 'professor', 'got', 'like', 'riddle',\n",
       "        'weasley', 'around', 'know', 'hagrid', 'dumbledore', 'go'],\n",
       "       dtype=object),\n",
       " array(['harry', 'prisoner', 'ron', 'hermione', 'azkaban', 'potter',\n",
       "        'lupin', 'harry potter', 'rowling', 'professor', 'black', 'back',\n",
       "        'one', 'hagrid', 'snape', 'around', 'like', 'looked', 'could',\n",
       "        'see', 'know', 'got', 'professor lupin', 'get', 'malfoy'],\n",
       "       dtype=object),\n",
       " array(['harry', 'potter', 'ron', 'fire', 'harry potter', 'goblet',\n",
       "        'hermione', 'rowling', 'dumbledore', 'back', 'mr', 'around',\n",
       "        'looked', 'one', 'moody', 'could', 'bagman', 'like', 'though',\n",
       "        'got', 'would', 'weasley', 'know', 'hagrid', 'crouch'],\n",
       "       dtype=object),\n",
       " array(['harry', 'potter order', 'order phoenix', 'potter', 'hermione',\n",
       "        'ron', 'phoenix', 'order', 'rowling', 'umbridge', 'back', 'sirius',\n",
       "        'well', 'dumbledore', 'could', 'know', 'professor', 'would',\n",
       "        'around', 'looked', 'like', 'one', 'got', 'though', 'looking'],\n",
       "       dtype=object),\n",
       " array(['harry', 'prince', 'half blood', 'dumbledore', 'ron', 'half',\n",
       "        'potter', 'blood', 'slughorn', 'harry potter', 'rowling',\n",
       "        'hermione', 'could', 'would', 'back', 'one', 'well', 'know',\n",
       "        'snape', 'malfoy', 'like', 'think', 'looked', 'time', 'see'],\n",
       "       dtype=object),\n",
       " array(['harry', 'deathly', 'hermione', 'ron', 'potter', 'harry potter',\n",
       "        'rowling', 'could', 'wand', 'dumbledore', 'back', 'know', 'like',\n",
       "        'would', 'one', 'voldemort', 'looked', 'around', 'still', 'think',\n",
       "        'eyes', 'death', 'snape', 'got', 'time'], dtype=object)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, feat = fit_transform_return(all_books, 0.2, 1.0, (1,4))\n",
    "get_all_top_tf_idf_words(x,feat, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd840d-3473-4ac8-8af6-9561d5d7f20d",
   "metadata": {},
   "source": [
    "We can see that we specify a lot of different parameters to extract the most important word in each book. Furthermore, we can see that the most of the time, the words \"Harry\", \"Potter\", \"Hermione\" or \"Ron\" come in the results. This is due to the fact that there are the main characters of the saga. However, if we want to have an interseting visualisation, we will have to get different words for each book. To do so, we can tune the parameters by first requiring that the document frequency must be strictly  below 1.0, i.e. the words doesn't appear in all the books. Furthermore, as already shown, we remove the most common english stopwords. Also, we added custom stopword such as 'said' or 'minds' that describe the process of talking in the book. Below, we consider a second version using a maximal document frequeny of 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738e84ec-6ec3-4bea-b794-ec7bc44fff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['quirrell', 'flamel', 'mr dursley', 'troll', 'professor quirrell',\n",
       "        'norbert', 'ronan', 'mrs dursley', 'piers', 'nicolas', 'firenze',\n",
       "        'turban', 'mr ollivander', 'bane', 'ollivander', 'unicorn',\n",
       "        'gotten', 'nimbus two', 'nicolas flamel', 'griphook',\n",
       "        'two thousand', 'nimbus two thousand', 'flint', 'nimbus',\n",
       "        'house cup', 'mr potter', 'sorcerer', 'scabbers', 'get yer',\n",
       "        'third floor'], dtype=object),\n",
       " array(['chamber secrets', 'secrets', 'lockhart', 'dobby', 'riddle',\n",
       "        'myrtle', 'diary', 'gilderoy', 'gilderoy lockhart', 'colin',\n",
       "        'justin', 'heir', 'basilisk', 'moaning myrtle', 'fawkes', 'lucius',\n",
       "        'elf', 'ernie', 'sir dobby', 'borgin', 'aragog', 'mr borgin',\n",
       "        'lucius malfoy', 'mandrakes', 'myrtle bathroom', 'heir slytherin',\n",
       "        'riddle diary', 'attacks', 'hospital wing', 'fifty years'],\n",
       "       dtype=object),\n",
       " array(['prisoner', 'azkaban', 'lupin', 'professor lupin', 'pettigrew',\n",
       "        'sirius', 'scabbers', 'crookshanks', 'dementors', 'buckbeak',\n",
       "        'trelawney', 'professor trelawney', 'marge', 'firebolt',\n",
       "        'aunt marge', 'hogsmeade', 'dementor', 'stan', 'peter', 'boggart',\n",
       "        'sirius black', 'map', 'hippogriff', 'rat', 'expecto', 'ern',\n",
       "        'james', 'rosmerta', 'lesson', 'patronus'], dtype=object),\n",
       " array(['moody', 'bagman', 'crouch', 'cedric', 'mr crouch', 'winky',\n",
       "        'krum', 'karkaroff', 'sirius', 'dobby', 'wormtail', 'maxime',\n",
       "        'madame maxime', 'rita', 'fleur', 'madame', 'diggory',\n",
       "        'tournament', 'skeeter', 'rita skeeter', 'beauxbatons', 'task',\n",
       "        'elf', 'frank', 'durmstrang', 'triwizard', 'eaters',\n",
       "        'death eaters', 'champion', 'viktor'], dtype=object),\n",
       " array(['potter order', 'order phoenix', 'phoenix', 'umbridge', 'sirius',\n",
       "        'professor umbridge', 'luna', 'lupin', 'kreacher',\n",
       "        'harry potter order', 'cho', 'tonks', 'moody', 'death eaters',\n",
       "        'eaters', 'trelawney', 'dementors', 'prophecy', 'angelina',\n",
       "        'bellatrix', 'james', 'grawp', 'dobby', 'elf',\n",
       "        'department mysteries', 'mundungus', 'professor trelawney',\n",
       "        'kingsley', 'department', 'marietta'], dtype=object),\n",
       " array(['prince', 'half blood', 'slughorn', 'riddle', 'prime minister',\n",
       "        'scrimgeour', 'prime', 'ogden', 'luna', 'kreacher', 'tonks',\n",
       "        'eaters', 'death eaters', 'prophecy', 'horcrux', 'borgin',\n",
       "        'zabini', 'bellatrix', 'lupin', 'horcruxes', 'narcissa', 'fleur',\n",
       "        'dark lord', 'eater', 'death eater', 'sirius',\n",
       "        'professor slughorn', 'hastily', 'hepzibah', 'room requirement'],\n",
       "       dtype=object),\n",
       " array(['deathly', 'griphook', 'luna', 'kreacher', 'lupin', 'eaters',\n",
       "        'death eaters', 'horcrux', 'bellatrix', 'fleur', 'locket',\n",
       "        'greyback', 'tonks', 'aberforth', 'grindelwald', 'bathilda',\n",
       "        'scrimgeour', 'yaxley', 'ollivander', 'muriel', 'horcruxes',\n",
       "        'doge', 'elder', 'tent', 'gregorovitch', 'lily', 'death eater',\n",
       "        'eater', 'godric hollow', 'kingsley'], dtype=object)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, feat = fit_transform_return(all_books, 0.2, 0.9, (1,6))\n",
    "words = get_all_top_tf_idf_words(x,feat, 30)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9131c2-a021-471b-9631-ce30b6c5529e",
   "metadata": {},
   "source": [
    "Just by removing the words or n-grams appearing in every book, we fall on meaningful words for each book. Indeed, we can see that all the words that appears for each book correspond to specific events that happen only in that book or not too often. Using the results we got, we will be able to produce the expected CloudWord visualisations and make it evolve over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb74e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save to json\n",
    "word_cloud_json = json.dumps(dict(zip(range(0, 7), [book.tolist() for book in words])))\n",
    "\n",
    "with open('../data/cleaned/word_cloud.json', 'w') as f:\n",
    "    f.write(word_cloud_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab63f05-56f1-43a2-a3fe-4342fa116cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle\n",
    "save_list(words)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71d2f77bccee14ca7852d7b7a1fa8ea4708b81087104d93973081337557f0ee6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
